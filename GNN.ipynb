{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Graph convolutional network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "classification on graphs is achieved by first embedding node features into a low dimensional space, then grouping nodes and summarizing them."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import TopKPooling\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "from torch_geometric.utils import (add_self_loops, sort_edge_index,\n",
    "                                   remove_self_loops)\n",
    "from torch_sparse import spspmm\n",
    "\n",
    "from net.braingraphconv import MyNNConv"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Network  is formed by three different types of layers: graph convolutional layers, node pooling layers and a readout layer.\n",
    " graph convolutional layer is used to probe the graph structure by using edge features, which contain important information about graphs. For example,the weights of the edges in brain fMRI graphs can represent the relationship between different ROIs.\n",
    " we define h(l)i ∈ R d(l) as the features for the ith node in the lth layer, where d(l) is the dimension of the lth layer features. The propagation\n",
    " model for the forward-pass update of node representation is calculated as:\n",
    " ![figure1](imag\\img1.png)\n",
    " Given an ROI ordering for all the graphs, we use one-hot encoding to represent the ROI’s location information, instead of using coordinates,because the nodes in the brain are aligned well. Specifically, for node vi, its ROI representation ri is a N−dimensional vector with 1 in the ith entry and 0 for the\n",
    "other entries.\n",
    "\n",
    " A node pooling layer is used to reduce the size of the graph, either by grouping the nodes together or pruning the original graph G to a subgraph Gsby keeping some important nodes only. We will focus on the pruning method,as it is more interpretable and can help detect biomarkers.\n",
    "A readout layer is used to summarize the node feature vectors {h(l)i} into a single vector z which is finally fed into a classifier for graph classification."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " Given node i’s regional information ri, such as the node’s coordinates in a mesh graph, we propose to learn the vectorized embedding kernel vec(Wi) based on ri on the lth Ra-GNN:\n",
    " ![figure1](imag\\img2.png)\n",
    " The ROIs in the same community will be embedded by the similar kernel so that nodes in different communities are embedded in different ways to reduce the number of learnable params.\n",
    "  ![figure1](imag\\img3.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Readout Layer\n",
    "Lastly, we seek a “flattening” operation to preserve information about the input graph in a fixed-size representation. Concretely, to summarize the output graph of the lth conv-pool block, (V(l), E(l)), we use:\n",
    "![figure1](imag\\imag4.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Network(torch.nn.Module):\n",
    "    def __init__(self, indim, ratio, nclass, k=8, R=200):\n",
    "        '''\n",
    "\n",
    "        :param indim: (int) node feature dimension\n",
    "        :param ratio: (float) pooling ratio in (0,1)\n",
    "        :param nclass: (int)  number of classes\n",
    "        :param k: (int) number of communities\n",
    "        :param R: (int) number of ROIs\n",
    "        '''\n",
    "        super(Network, self).__init__()\n",
    "\n",
    "        self.indim = indim\n",
    "        self.dim1 = 32\n",
    "        self.dim2 = 32\n",
    "        self.dim3 = 512\n",
    "        self.dim4 = 256\n",
    "        self.dim5 = 8\n",
    "        self.k = k\n",
    "        self.R = R\n",
    "\n",
    "        self.n1 = nn.Sequential(nn.Linear(self.R, self.k, bias=False), nn.ReLU(), nn.Linear(self.k, self.dim1 * self.indim))\n",
    "        self.conv1 = MyNNConv(self.indim, self.dim1, self.n1, normalize=False)\n",
    "        self.pool1 = TopKPooling(self.dim1, ratio=ratio, multiplier=1, nonlinearity=torch.sigmoid)\n",
    "        self.n2 = nn.Sequential(nn.Linear(self.R, self.k, bias=False), nn.ReLU(), nn.Linear(self.k, self.dim2 * self.dim1))\n",
    "        self.conv2 = MyNNConv(self.dim1, self.dim2, self.n2, normalize=False)\n",
    "        self.pool2 = TopKPooling(self.dim2, ratio=ratio, multiplier=1, nonlinearity=torch.sigmoid)\n",
    "\n",
    "\n",
    "        self.fc1 = torch.nn.Linear((self.dim1+self.dim2)*2, self.dim2)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(self.dim2)\n",
    "        self.fc2 = torch.nn.Linear(self.dim2, self.dim3)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(self.dim3)\n",
    "        self.fc3 = torch.nn.Linear(self.dim3, nclass)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index, batch, edge_attr, pos):\n",
    "\n",
    "        x = self.conv1(x, edge_index, edge_attr, pos)\n",
    "        x, edge_index, edge_attr, batch, perm, score1 = self.pool1(x, edge_index, edge_attr, batch)\n",
    "\n",
    "        pos = pos[perm]\n",
    "        x1 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "\n",
    "        edge_attr = edge_attr.squeeze()\n",
    "        edge_index, edge_attr = self.augment_adj(edge_index, edge_attr, x.size(0))\n",
    "\n",
    "        x = self.conv2(x, edge_index, edge_attr, pos)\n",
    "        x, edge_index, edge_attr, batch, perm, score2 = self.pool2(x, edge_index,edge_attr, batch)\n",
    "\n",
    "        x2 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "\n",
    "        x = torch.cat([x1,x2], dim=1)\n",
    "        x = self.bn1(F.relu(self.fc1(x)))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.bn2(F.relu(self.fc2(x)))\n",
    "        x= F.dropout(x, p=0.5, training=self.training)\n",
    "        x = F.log_softmax(self.fc3(x), dim=-1)\n",
    "\n",
    "        return x,self.pool1.weight,self.pool2.weight, torch.sigmoid(score1).view(x.size(0),-1), torch.sigmoid(score2).view(x.size(0),-1)\n",
    "\n",
    "    def augment_adj(self, edge_index, edge_weight, num_nodes):\n",
    "        edge_index, edge_weight = add_self_loops(edge_index, edge_weight,\n",
    "                                                 num_nodes=num_nodes)\n",
    "        edge_index, edge_weight = sort_edge_index(edge_index, edge_weight,\n",
    "                                                  num_nodes)\n",
    "        edge_index, edge_weight = spspmm(edge_index, edge_weight, edge_index,\n",
    "                                         edge_weight, num_nodes, num_nodes,\n",
    "                                         num_nodes)\n",
    "        edge_index, edge_weight = remove_self_loops(edge_index, edge_weight)\n",
    "        return edge_index, edge_weight\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
